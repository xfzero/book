#### 1. 关闭服务

**Crtl+C关闭：**

如果是以前台方式启动的mongodb服务，则可以额使用“Crtl+C”关闭服务。

这种方式会等待当前进行中的操作完成，是一种干净的关闭方式。

**使用数据库命名关闭：**

需要切到admin数据库后关闭

```sh
>use admin
>db.shutdownServer()
```

**使用mongod命令：**

mongod **--shutdown** --dbpath /database/mongodb/data/

**使用kill命令:**

```sh
[mongo@redhatB data]$ ps -ef | grep mongo
root     17573 14213  0 05:10 pts/1    00:00:00 su - mongo
mongo    17574 17573  0 05:10 pts/1    00:00:00 -bash
mongo    18288     1  0 06:12 ?        00:00:00 mongod -f /database/mongodb/data/mongodb_27017.conf
mongo    18300 17574  6 06:13 pts/1    00:00:00 ps -ef
mongo    18301 17574  0 06:13 pts/1    00:00:00 grep mongo

#kill 18288

```

备注：可以使用操作系统的 kill 命令，给 mongod 进程发送 SIGINT 或 SIGTERM 信号，即 "kill -2 PID," 或者 “kill -15 PID“。

建议不要使用 ”kill -9 pid“，因为如果 MongoDB 运行在没开启日志（--journal）的情况下，可能会造成数据损失。

如果使用-9命名后导致启动不了服务，需要删除mongodb目录下的mongod.lock文件，并做一定的数据恢复操作。

#### 2. 内存数据库

**redis和mysql:**
redis：是内存数据库，所有数据都是放在内存中的，持久化是使用RDB方式或者aof方式。
mysql：无论数据还是索引都存放在硬盘中。到要使用的时候才交换到内存中。能够处理远超过内存总量的数据。

**mongodb:**
mongodb的操作大部分都在内存中。但mongodb并不是单纯的内存数据库，从数据存储原理来看其实更像是硬盘数据库。

mongodb的所有数据实际上是存放在硬盘的，所有要操作的数据通过mmap的方式映射到内存某个区域内。
然后，mongodb就在这块区域里面进行数据修改，避免了零碎的硬盘操作。
至于mmap上的内容flush到硬盘就是操作系统的事情了，所以，如果，mongodb在内存中修改了数据，然后，mmap数据flush到硬盘之前，系统当机了，就会丢失数据了。

**数据量和性能:**
当物理内存够用的时候：
redis》mongodb》mysql

当物理内存不够用的时候：
redis和mongodb都会使用虚拟内存。

实际上如果redis要开始虚拟内存，那很明显要么加内存条，要么你换个数据库了。

但是，mongodb不一样，只要，业务上能保证，冷热数据的读写比，使得热数据在物理内存中，mmap的交换较少。mongodb还是能够保证性能。有人使用mongodb存储了上T的数据。

mysql，mysql根本就不需要担心数据量跟内存下的关系。不过，内存的量跟热数据的关系会极大地影响性能表现。

简单来说就是：
mmap系统调用并不是完全为了用于共享内存而设计的。它本身提供了不同于一般对普通文件的访问方式，进程可以像读写内存一样对普通文件的操作。

mmap系统调用使得进程之间通过映射同一个普通文件实现共享内存。普通文件被映射到进程地址空间后，进程可以像访问普通内存一样对文件进行访问，不必再调用read()，write（）等操作。mmap并不分配空间, 只是将文件映射到调用进程的地址空间里, 然后你就可以用memcpy等操作写文件, 而不用write()了.写完后用msync()同步一下, 你所写的内容就保存到文件里了. 不过这种方式没办法增加文件的长度, 因为要映射的长度在调用mmap()的时候就决定了.



#### 3. 脚本

mongo客户端有两种方式与mongodb服务进行交互,一种是mongo shell,一种是执行javascript脚本。

**js脚本：**

```js
//demo1：
var url = "mongodb://localhost:27017/test";
var db = connect(url);
var obj = db.student.findOne()
print("查询结果为:")
printjson(obj)

//demo2:
const conn = new Mongo('localhost:27017');
print(`连接: ${conn}`)
let db = conn.getDB('test');
print(`当前数据库：${db}`);
const dbs = db.adminCommand('listDatabases');
print('显示所有的数据库:')
printjson(dbs);
const collections = db.getCollectionNames();
print(`${db}中的collections:`);
printjson(collections);
db = db.getSiblingDB('test');
print(`切换数据库为${db}`);

//demo3:
const conn = new Mongo('localhost:27017')
print(`链接：${conn}`)
let db = conn.getDB('test')
print(`当前数据库：${db}`)
let recod = {id:10003,name:"rob"}
let result = db.student.insert(recod)
print(result)
let students = db.student.find()
students.forEach(function(stu){
	printjson(stu);
})
```

**shell脚本：**

设置副本集:

```sh
#mongodb 进入client 并use admin
cd /usr/mongodb/bin
MongoDB='./mongo 192.168.1.7:37017'
$MongoDB <<EOF
use admin
rsconf={
        "_id" : "Job001",
        "members" : [
            {
                "_id" : 0,
                "host" : "192.168.1.7:37017"
            }
        ]
    }
rs.initiate(rsconf)
rs.add("192.168.1.8:37017")
rs.add("192.168.1.9:37017")
exit;
EOF
```

修改副本集里mongodb的优先级:

```sh
#!/bin/bash
#mongodb 进入client 并进入primary
cd /usr/mongodb/bin
MongoDB='./mongo 192.168.1.7:37017'
$MongoDB <<EOF
use MongoModelJobResume
#rs.status()
cfg=rs.conf()
cfg.members[0].priority=99
cfg.members[1].priority=50
cfg.members[2].priority=30
rs.reconfig(cfg)
rs.conf()
exit;
EOF
```

把一个表转到临时表，再拷贝回来，这样oplog中就会重新生成新的完整log（前提是oplog要足够大）:

```sh
#!/bin/bash
#mongodb 进入client 并进入primary
cd /usr/mongodb/bin
MongoDB='./mongo 192.168.1.7:37017'
$MongoDB <<EOF
use MongoModelJobResume
rs.remove("192.168.1.8:37017")
rs.remove("192.168.1.9:37017")
db.tbJobResume.renameCollection("tbJobResumeOld")
db.tbJobResumeOld.copyTo("tbJobResume")
rs.add("192.168.1.8:37017")
rs.add("192.168.1.9:37017")
#db.tbJobResumeOld.drop()
exit;
EOF
```

按照日期生成mongodb日志(配合crontab 按每天的日期生成log):

```sh
#!/bin/bash
#mongodb client  use admin
cd /usr/mongodb/bin
MongoDB='./mongo 192.168.1.7:37017'
$MongoDB <<EOF
use admin
db.runCommand( { logRotate : 1 } )
exit;
EOF
```

自动备份并且压缩:

```sh
#!/bin/bash
filename=`date +%Y%m%d%H`
backmongodbFile=mongodb$filename.tar.gz
cd /home/mongo/back/
/usr/mongodb/bin/mongodump -h 192.168.1.7 -port 37017 -d MongoDBAgent -o mongodb_dump/
/usr/mongodb/bin/mongodump -h 192.168.1.7 -port 37017 -d MongoDBBg -o mongodb_dump/
/usr/mongodb/bin/mongodump -h 192.168.1.7 -port 37017 -d MongoModelActor -o mongodb_dump/
tar czf $backmongodbFile  mongodb_dump/
rm mongodb_dump -rf
```

自动解压并还原数据:

```sh
#!/bin/bash
filename='20150330013'
backmongodbFile=mongodb$filename.tar.gz
cd /home/mongo/back/
tar zxvf $backmongodbFile
/usr/mongodb/bin/mongorestore -h 192.168.1.6 -port 37017 --drop -d MongoDBAgent mongodb_dump/MongoDBAgent
/usr/mongodb/bin/mongorestore -h 192.168.1.6 -port 37017 --drop -d MongoDBBg mongodb_dump/MongoDBBg
/usr/mongodb/bin/mongorestore -h 192.168.1.6 -port 37017 --drop -d MongoModelActor mongodb_dump/MongoModelActor
rm mongodb_dump -rf
```



#### 4.  常用方法

```sh
show dbs

use test1 #无则创建,不会真的创建数据库，直到在其下插入数据或创建集合时才创建库

db.dropDatabase()

show collections

db.createCollection("students")

#db.students.renameCollection("students2")

db.students.drop()

db.students.createIndex({"id": 1})

db.students.getIndexes()

db.students.insert({id: 10001,name: 'tony',age: 18,mob: 15000001})

db.students.dropIndex("id_1")

db.students.createIndex({"id": 1},{unique: true,background: true})

db.students.find().pretty().sort({id:1}).skip(1).limit(1)
```

```sh
db.stats() #来确认已使用空间和已分配空间。
db.colection.stats() #确认某个集合的使用量
```

```sh
db.cappedLogCollection.isCapped() #判断集合是否为固定集合
db.runCommand({"convertToCapped":"posts",size:10000}) #将已存在的集合转换为固定集合

#固定集合文档按照插入顺序储存的,默认情况下查询就是按照插入顺序返回的,也可以使用$natural调整返回顺序。
db.cappedLogCollection.find().sort({$natural:-1}) 
```



#### 5. 文档存储

当Client端要将写入文档，使用查询等等操作时，需要将文档编码为BSON格式，然后再发送给Server端。同样，Server端的返回结果也是编码为BSON格式再放回给Client端

**数据库是如何跟底层系统打交道的：**

- 内存映射文件是OS通过mmap在内存中创建一个数据文件，这样就把文件映射到一个虚拟内存的区域。
- 虚拟内存对于进程来说，是一个物理内存的抽象，寻址空间大小为2^64
- 操作系统通过mmap来把进程所需的所有数据映射到这个地址空间(红线)，然后再把当前需要处理的数据映射到物理内存(灰线)
- 当进程访问某个数据时，如果数据不在虚拟内存里，触发page fault，然后OS从硬盘里把数据加载进虚拟内存和物理内存
- 如果物理内存满了，触发swap-out操作，这时有些数据就需要写回磁盘，如果是纯粹的内存数据，写回swap分区，如果不是就写回磁盘。
- 有了内存映射文件，要访问的数据就好像都在内存里面，简单化了MongoDB访问和修改数据的逻辑
- MongoDB读写都只是和虚拟内存打交道，剩下都交给OS打理
- 虚拟内存大小=所有文件大小+其他一些开销(连接，堆栈)
- 如果journal开启，虚拟内存大小差不多翻番
- 使用MMF的好处1：不用自己管理内存和磁盘调度2：LRU策略3：重启过程中，Cache依然在。
- 使用MMF的坏处1：RAM使用会受磁盘碎片的影响，高预读也会影响2：无法自己优化调度算法，只能使用LRU

#### 6.  集合上限

默认情况下，MongoDB 的每个数据库的命名空间保存在一个 16MB 的 .ns 文件中，平均每个命名占用约 628 字节，也即整个数据库的命名空间的上限约为 24000。

每一个集合、索引都将占用一个命名空间。所以，如果每个集合有一个索引（比如默认的 _id 索引），那么最多可以创建 12000 个集合。如果索引数更多，则可创建的集合数就更少了。同时，如果集合数太多，一些操作也会变慢。

不过，如果真的需要建立更多的集合的话，MongoDB 也是支持的，只需要在启动时加上“--nssize”参数，这样对应数据库的命名空间文件就可以变得更大以便保存更多的命名。这个命名空间文件（.ns 文件）最大可以为 2G，也就是说最大可以支持约 340 万个命名，如果每个集合有一个索引的话，最多可创建约 170 万个集合。

还需要注意，--nssize 只设置新创建的 .ns 文件的大小，如果想改变已经存在的数据库的命名空间，在使用这个参数启动后，还需要运行 db.repairDatabase() 命令来调整尺寸。

#### 7. 预分配空间

预分配的方式可以减少碎片，程序申请磁盘空间的时候更高效，但MongoDB预分配的策略可能导致空间的浪费。默认的分配空间的策略是：随着数据库数据的增加，MongoDB会不断分配更多的数据文件。每个新数据文件的大小都是上一个已分配文件的两倍( 64M, 128M, 256M, 512M, 1G, 2G, 2G, 2G )，直到预分配文件大小的上限2G。虽然2G的阀值可以调整，但一般运维等时候往往也不会去调整，就这点来说，可能导致空间的浪费。（可以这样理解，原本一个collection大小为2M，增加了一个100K的数据后，现在该collection大小变为2M*2=4M,这种分配策略会浪费内存，但会避免产生碎片。

